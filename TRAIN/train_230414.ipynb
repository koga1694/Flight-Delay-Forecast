{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "class Processing:\n",
    "    def __init__(self, x, test): # 이후 테스트 데이터도 넣는 버전 만들어야함\n",
    "        self.x = x\n",
    "        self.test = test\n",
    "    \n",
    "    def to_time(self, data, where = None):\n",
    "        if where == None:\n",
    "            print('where 넣어야함')\n",
    "            return None\n",
    "        \n",
    "        def to_time(time_list):\n",
    "            if where == 'first':\n",
    "                Time = pd.Series(time_list).astype(str).str.zfill(4)\n",
    "                Time = Time.replace('2400','0000')\n",
    "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") if i != '0nan' else np.NaN for i in Time]\n",
    "            \n",
    "            elif where == 'twice':\n",
    "                Time = pd.Series(time_list)\n",
    "                Time = Time.replace('2400','0000')\n",
    "                # Time = Time.replace('9999','1557')\n",
    "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") for i in Time]  \n",
    "        \n",
    "        def time_gb(x):\n",
    "            if x < 600:\n",
    "                return '0000-0600'\n",
    "            elif x >= 600 and x <= 659:\n",
    "                return '0600-0659'\n",
    "            elif x>=1400 and x<=1459:\n",
    "                return '1400-1459'\n",
    "            elif x>=1200 and x<=1259:\n",
    "                return '1200-1259'\n",
    "            elif x>=1500 and x<=1559:\n",
    "                return '1500-1559'\n",
    "            elif x>=1900 and x<=1959:\n",
    "                return '1900-1959'\n",
    "            elif x>=900 and x<=959:\n",
    "                return '0900-0959'\n",
    "            elif x>=1000 and x<=1059:\n",
    "                return  '1000-1059'\n",
    "            elif x>=2000 and x<=2059:\n",
    "                return '2000-2059'\n",
    "            elif x>=1300 and x<=1359:\n",
    "                return '1300-1359'\n",
    "            elif x>=1100 and x<=1159:\n",
    "                return '1100-1159'\n",
    "            elif x>=800 and x<=859:\n",
    "                return '0800-0859'\n",
    "            elif x>=2200 and x<=2259:\n",
    "                return '2200-2259'\n",
    "            elif x>=1600 and x<=1659:\n",
    "                return '1600-1659'\n",
    "            elif x>=1700 and x<=1759:\n",
    "                return '1700-1759'\n",
    "            elif x>=2100 and x<=2159:\n",
    "                return '2100-2159'\n",
    "            elif x>=700 and x<=759:\n",
    "                return '0700-0759'\n",
    "            elif x>=1800 and x<=1859:\n",
    "                return '1800-1859'\n",
    "            elif x>=1 and x<=559:\n",
    "                return '0001-0559'\n",
    "            elif x>=2300 and x<=2400:\n",
    "                return '2300-2400'\n",
    "            \n",
    "        def distance_gb(x):\n",
    "            if x < 700 :\n",
    "                return 'short_route'\n",
    "            elif x>=700 and x<3000:\n",
    "                return 'mid_route'\n",
    "            elif x>=3000:\n",
    "                return 'long_route'    \n",
    "        \n",
    "        if where == 'first':\n",
    "            time_list = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Departure_Time'] ]\n",
    "            time_list1 = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Arrival_Time'] ]\n",
    "            \n",
    "        elif where == 'twice':\n",
    "            time_list = [i for i in data['Estimated_Departure_Time']]\n",
    "            time_list1 = [i for i in data['Estimated_Arrival_Time']]\n",
    "        data['Estimated_Departure_Time_HH:MM'] = to_time(time_list)\n",
    "        data['Estimated_Arrival_Time_HH:MM'] = to_time(time_list1)\n",
    "    \n",
    "        \n",
    "        # 예상 비행시간 만들기 (분으로 만들기)\n",
    "        data_est_time = []\n",
    "        for i,j in zip(data['Estimated_Arrival_Time_HH:MM'], data['Estimated_Departure_Time_HH:MM']):\n",
    "            if str(i) != 'nan' and str(j) != 'nan':\n",
    "                if (datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60 >= 0:\n",
    "                    data_est_time.append((datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60)\n",
    "                else:\n",
    "                    time = datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\") + datetime.strptime('23:59', \"%H:%M\") + timedelta(minutes=1)\n",
    "                    data_est_time.append(timedelta(hours=time.hour,minutes=time.minute ).total_seconds()/60)\n",
    "            else:\n",
    "                data_est_time.append(np.NaN)\n",
    "        \n",
    "        if where == 'first':\n",
    "            data['Estimated_Time'] = data_est_time\n",
    "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].dropna().apply(time_gb)\n",
    "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].dropna().apply(time_gb)\n",
    "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
    "            \n",
    "        elif where == 'twice':\n",
    "            data['Estimated_Time'] = data_est_time\n",
    "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].astype(int).apply(time_gb)\n",
    "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].astype(int).apply(time_gb)\n",
    "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fill_airline_and_id(self, data):\n",
    "        \n",
    "        for airline in data['Airline'].dropna().unique():\n",
    "            id = data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'].dropna().unique()\n",
    "            data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'] = id[0]\n",
    "                \n",
    "\n",
    "        for id in data['Carrier_ID(DOT)'].dropna().unique():\n",
    "            airline = data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'].dropna().unique()\n",
    "            data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'] = airline[0]\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def fill_state(self, data):\n",
    "        for id in data['Origin_Airport_ID'].dropna().unique():\n",
    "            # 테스트셋에 알수없는 Origin State -> dummy로 채움\n",
    "            try:\n",
    "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'].dropna().unique()[0]\n",
    "            except:\n",
    "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = 'dummy'\n",
    "        \n",
    "        for id in data['Destination_Airport_ID'].dropna().unique():\n",
    "            try:\n",
    "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'].dropna().unique()[0]\n",
    "            except: # 기록이 하나밖에 없음. Youngstown (YNG 공항)\n",
    "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = 'Youngstown'\n",
    "        return data\n",
    "        \n",
    "    def fill_timedata(self, data, where=None):\n",
    "        if where == 'at':\n",
    "            time1 = 'Estimated_Departure_Time'\n",
    "            time2 = 'Estimated_Arrival_Time'\n",
    "            \n",
    "        elif where == 'dt':\n",
    "            time1 = 'Estimated_Arrival_Time'\n",
    "            time2 = 'Estimated_Departure_Time'\n",
    "            \n",
    "        elif where == 'both':\n",
    "            b_data = data[~((data['Estimated_Arrival_Time'].isna()) & (data['Estimated_Departure_Time'].isna()))]\n",
    "            b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
    "            b_data = b_data.reset_index()\n",
    "            b_data = b_data.rename(columns={0:'count'})\n",
    "            b_data = b_data.sort_values(['Origin_Airport', 'Destination_Airport', 'count'], ascending=False)\n",
    "            b_data = b_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport'], keep='first')\n",
    "\n",
    "            b_data = b_data.set_index(['Origin_Airport', 'Destination_Airport']).drop('count', axis=1)\n",
    "\n",
    "            b = data[(data['Estimated_Arrival_Time'].isna()) & (data['Estimated_Departure_Time'].isna())]\n",
    "            b = b.set_index(['Origin_Airport', 'Destination_Airport'])\n",
    "\n",
    "            b[['Estimated_Arrival_Time', 'Estimated_Departure_Time']] = b_data[['Estimated_Arrival_Time', 'Estimated_Departure_Time']]\n",
    "            \n",
    "            return b.reset_index()\n",
    "        \n",
    "        else:\n",
    "            print('Where 값을 채워주세요. at: 도착시간 보간, dt: 출발시간 보간')\n",
    "            return None\n",
    "            \n",
    "            \n",
    "        \n",
    "        # 같은 출발/도착시간이 있을 경우 가장 많은 출발/도착시간으로 채움\n",
    "        merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
    "        merge_data = merge_data.reset_index()\n",
    "        merge_data = merge_data.rename(columns={0:'count'})\n",
    "        merge_data = merge_data[~((merge_data[time1].isna()) & (merge_data[time2].isna()))]\n",
    "        merge_data = merge_data.sort_values(['Origin_Airport', 'Destination_Airport', 'count'], ascending=False)\n",
    "        merge_data = merge_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', time1], keep='first')\n",
    "        mt = data.loc[(data[time2].isna()) & ~(data[time1].isna()), ['Origin_Airport', 'Destination_Airport',time2, time1]]\n",
    "        mt = mt.drop(time2, axis=1)\n",
    "        mt = pd.merge(mt, merge_data, how='left', on =['Origin_Airport', 'Destination_Airport', time1])\n",
    "\n",
    "        # 같은 출발/도착시간이 없을 경우 출도착공항 Estimated_Time이 가장 많은 시간을 채우고 출발/도착시간을 계산\n",
    "        et = merge_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[['Estimated_Time']].value_counts()\n",
    "        et = et.reset_index()\n",
    "        et = et.rename(columns={0:'count'})\n",
    "        et = et.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
    "        et = et.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline'], keep='first').drop(['count'], axis=1)\n",
    "        mt2 = mt[mt[time2].isna()].drop(['Estimated_Time', 'count'], axis=1)\n",
    "        mt2 = pd.merge(mt2, et, how='left', on =['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "\n",
    "        # # mt2-mt 합침\n",
    "        mt= mt.set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "        mt2= mt2.reset_index().set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "        mt.loc[mt['Estimated_Time'].isna(), 'Estimated_Time'] = mt2['Estimated_Time']\n",
    "\n",
    "        # # mt-data 합침 (따로 분리하여 나중에 한번에 채움. 보간한 값을 보간할 때 사용하지 않기 위함)\n",
    "        mt = mt.drop('count', axis=1).reset_index().set_index(['Origin_Airport', 'Destination_Airport', time1])\n",
    "        fill_data = data[~(data[time1].isna()) & (data[time2].isna())]\n",
    "        fill_data = fill_data.set_index(['Origin_Airport', 'Destination_Airport', time1])\n",
    "        fill_data[[time2, 'Estimated_Time']] = mt[[time2, 'Estimated_Time']]\n",
    "        fill_data = fill_data.reset_index()\n",
    "    \n",
    "        return fill_data\n",
    "    \n",
    "    # 시간 채우는 함수\n",
    "    def fill_time(self, data, where = None):\n",
    "        at_data = self.fill_timedata(data, where='at')\n",
    "        dt_data = self.fill_timedata(data, where='dt')\n",
    "        b_data = self.fill_timedata(data, where='both')\n",
    "\n",
    "        data = data.set_index('ID')\n",
    "        at_data = at_data.set_index('ID')\n",
    "        dt_data = dt_data.set_index('ID')\n",
    "        b_data = b_data.set_index('ID')\n",
    "        \n",
    "        data.loc[(data['Estimated_Arrival_Time'].isna()) & ~(data['Estimated_Departure_Time'].isna()), ['Estimated_Arrival_Time', 'Estimated_Time']] = at_data[['Estimated_Arrival_Time', 'Estimated_Time']]\n",
    "        data.loc[(data['Estimated_Departure_Time'].isna())  & ~(data['Estimated_Arrival_Time'].isna()), ['Estimated_Departure_Time', 'Estimated_Time']] = dt_data[['Estimated_Departure_Time', 'Estimated_Time']]\n",
    "        data.loc[(data['Estimated_Departure_Time'].isna()) & (data['Estimated_Arrival_Time'].isna()), ['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']] = b_data[['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']]\n",
    "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].fillna(9999).astype(int).astype(str)\n",
    "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].str.zfill(4)\n",
    "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].fillna(9999).astype(int).astype(str)\n",
    "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].str.zfill(4)\n",
    "        \n",
    "        # apply용 함수\n",
    "        def arr_time(x):\n",
    "            try:\n",
    "                x['Estimated_Departure_Time'] = x['Estimated_Departure_Time'].replace('2400','0000')\n",
    "                time = datetime.strptime(x['Estimated_Departure_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
    "                hour = str(time.hour)\n",
    "                minute = str(time.minute)\n",
    "                x['Estimated_Arrival_Time'] = hour+minute        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return x\n",
    "\n",
    "        def dep_time(x):\n",
    "            try:\n",
    "                x['Estimated_Arrival_Time'] = x['Estimated_Arrival_Time'].replace('2400','0000')\n",
    "                time = datetime.strptime(x['Estimated_Arrival_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
    "                hour = str(time.hour)\n",
    "                minute = str(time.minute)\n",
    "                x['Estimated_Departure_Time'] = hour+minute        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        add_time = data.loc[(data['Estimated_Arrival_Time'] == '9999') & (data['Estimated_Departure_Time'] != '9999'), ['Estimated_Departure_Time', 'Estimated_Time', 'Estimated_Arrival_Time']]\n",
    "        t = add_time.apply(arr_time, axis=1)\n",
    "        t= t[~t['Estimated_Time'].isna()]\n",
    "        data.loc[t.index, 'Estimated_Arrival_Time'] = t['Estimated_Arrival_Time']\n",
    "        \n",
    "        add_time = data.loc[(data['Estimated_Arrival_Time'] != '9999') & (data['Estimated_Departure_Time'] == '9999'), ['Estimated_Arrival_Time', 'Estimated_Time', 'Estimated_Departure_Time']]\n",
    "        t = add_time.apply(dep_time, axis=1)\n",
    "        t= t[~t['Estimated_Time'].isna()]\n",
    "        data.loc[t.index, 'Estimated_Departure_Time'] = t['Estimated_Departure_Time']\n",
    "        \n",
    "        if where == 'test':\n",
    "            test = data[~data['Estimated_Time'].isna()]\n",
    "            test = data[data['Estimated_Time'] != 'nan']\n",
    "            test = test[test['Estimated_Arrival_Time'] != '9999']\n",
    "            test = test[test['Estimated_Departure_Time'] != '9999']\n",
    "            \n",
    "            return test, data\n",
    "            \n",
    "\n",
    "        data = data[~data['Estimated_Time'].isna()]\n",
    "        data = data[data['Estimated_Time'] != 'nan']\n",
    "\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def train_processing(self):\n",
    "        data = self.fill_airline_and_id(self.x)\n",
    "        data = self.fill_state(data)\n",
    "        data = self.to_time(data, where='first')\n",
    "        data = self.fill_time(data)\n",
    "        data = self.to_time(data, where='twice')\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def test_processing(self):\n",
    "        data = self.fill_airline_and_id(self.test)\n",
    "        data = self.fill_state(data)\n",
    "        data = self.to_time(data, where='first')\n",
    "        data, origin = self.fill_time(data, where='test')\n",
    "        data = self.to_time(data, where='twice')\n",
    "        # return data\n",
    "    \n",
    "        return data, origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:176: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:176: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:154: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:176: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:176: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\signlab026\\AppData\\Local\\Temp\\ipykernel_12300\\2017646892.py:154: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n"
     ]
    }
   ],
   "source": [
    "pc = Processing(data, test)\n",
    "\n",
    "train = pc.train_processing()\n",
    "test, origin = pc.test_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE(x):\n",
    "    x = x.drop(['Carrier_Code(IATA)', 'Cancelled', 'Diverted', 'Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
    "    x['edt_h'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
    "    x['edt_m'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
    "    x['eat_h'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
    "    x['eat_m'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
    "\n",
    "    x = x.drop(['Estimated_Departure_Time_HH:MM', 'Estimated_Arrival_Time_HH:MM'], axis=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "train = FE(train)\n",
    "test = FE(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month                          0\n",
      "Day_of_Month                   0\n",
      "Origin_Airport                 0\n",
      "Origin_Airport_ID              0\n",
      "Origin_State                   0\n",
      "Destination_Airport            0\n",
      "Destination_Airport_ID         0\n",
      "Destination_State              0\n",
      "Distance                       0\n",
      "Airline                    11391\n",
      "Carrier_ID(DOT)            11391\n",
      "Tail_Number                    0\n",
      "Delay                     715743\n",
      "Estimated_Time                 0\n",
      "Dep_time_gb                    0\n",
      "Arr_time_gb                    0\n",
      "route_gb                       0\n",
      "edt_h                          0\n",
      "edt_m                          0\n",
      "eat_h                          0\n",
      "eat_m                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isna().sum())\n",
    "train[['Airline', 'Carrier_ID(DOT)']] = train[['Airline', 'Carrier_ID(DOT)']].fillna('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month                         0\n",
      "Day_of_Month                  0\n",
      "Origin_Airport                0\n",
      "Origin_Airport_ID             0\n",
      "Origin_State                  0\n",
      "Destination_Airport           0\n",
      "Destination_Airport_ID        0\n",
      "Destination_State             0\n",
      "Distance                      0\n",
      "Airline                   10416\n",
      "Carrier_ID(DOT)           10416\n",
      "Tail_Number                   0\n",
      "Estimated_Time                0\n",
      "Dep_time_gb                   0\n",
      "Arr_time_gb                   0\n",
      "route_gb                      0\n",
      "edt_h                         0\n",
      "edt_m                         0\n",
      "eat_h                         0\n",
      "eat_m                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.isna().sum())\n",
    "test[['Airline', 'Carrier_ID(DOT)']] = test[['Airline', 'Carrier_ID(DOT)']].fillna('dummy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month                          0\n",
      "Day_of_Month                   0\n",
      "Origin_Airport                 0\n",
      "Origin_Airport_ID              0\n",
      "Origin_State                   0\n",
      "Destination_Airport            0\n",
      "Destination_Airport_ID         0\n",
      "Destination_State              0\n",
      "Distance                       0\n",
      "Airline                        0\n",
      "Carrier_ID(DOT)                0\n",
      "Tail_Number                    0\n",
      "Delay                     715743\n",
      "Estimated_Time                 0\n",
      "Dep_time_gb                    0\n",
      "Arr_time_gb                    0\n",
      "route_gb                       0\n",
      "edt_h                          0\n",
      "edt_m                          0\n",
      "eat_h                          0\n",
      "eat_m                          0\n",
      "dtype: int64\n",
      "Month                     0\n",
      "Day_of_Month              0\n",
      "Origin_Airport            0\n",
      "Origin_Airport_ID         0\n",
      "Origin_State              0\n",
      "Destination_Airport       0\n",
      "Destination_Airport_ID    0\n",
      "Destination_State         0\n",
      "Distance                  0\n",
      "Airline                   0\n",
      "Carrier_ID(DOT)           0\n",
      "Tail_Number               0\n",
      "Estimated_Time            0\n",
      "Dep_time_gb               0\n",
      "Arr_time_gb               0\n",
      "route_gb                  0\n",
      "edt_h                     0\n",
      "edt_m                     0\n",
      "eat_h                     0\n",
      "eat_m                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isna().sum())\n",
    "\n",
    "print(test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Carrier_ID(DOT)'] = train['Carrier_ID(DOT)'].astype(str)\n",
    "test['Carrier_ID(DOT)'] = test['Carrier_ID(DOT)'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_ar = train.__deepcopy__().drop(['Destination_Airport_ID', 'Origin_Airport_ID'], axis=1)\n",
    "test_ar = test.__deepcopy__().drop(['Destination_Airport_ID', 'Origin_Airport_ID'], axis=1)\n",
    "\n",
    "train_ar['Carrier_ID(DOT)'] = train_ar['Carrier_ID(DOT)'].astype(str)\n",
    "test_ar['Carrier_ID(DOT)'] = test_ar['Carrier_ID(DOT)'].astype(str)\n",
    "\n",
    "label_st = train_ar.drop(columns = ['Delay'])\n",
    "train_st = train_ar[~(train_ar['Delay'].isna()) & (train_ar['route_gb'] != 'long_route')]\n",
    "test_st = test_ar[test_ar['route_gb'] != 'long_route']\n",
    "X_nan = train_ar[(train_ar['Delay'].isna()) & (train_ar['route_gb'] != 'long_route')]\n",
    "\n",
    "qual_col = ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline', 'Carrier_ID(DOT)', 'Tail_Number', 'Dep_time_gb',\t'Arr_time_gb',\t'route_gb']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train[i])\n",
    "    train_st[i]=le.transform(train_st[i])\n",
    "    X_nan[i]=le.transform(X_nan[i])\n",
    "    \n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_st[i]=le.transform(test_st[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_data = TabularDataset(train_st)\n",
    "unlabeled_data = TabularDataset(X_nan)\n",
    "test_data = TabularDataset(test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230414_073037\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230414_073037\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19044\n",
      "Train Data Rows:    244468\n",
      "Train Data Columns: 18\n",
      "Label Column: Delay\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Not_Delayed, class 0 = Delayed\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Not_Delayed) vs negative (Delayed) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5082.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 99.74 MB (2.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  2 | ['Distance', 'Estimated_Time']\n",
      "\t\t('int', [])   : 16 | ['Month', 'Day_of_Month', 'Origin_Airport', 'Origin_State', 'Destination_Airport', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  2 | ['Distance', 'Estimated_Time']\n",
      "\t\t('int', [])       : 15 | ['Month', 'Day_of_Month', 'Origin_Airport', 'Origin_State', 'Destination_Airport', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['route_gb']\n",
      "\t1.2s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 96.87 MB (1.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1199.21s of the 3598.54s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-1.3275\t = Validation score   (-log_loss)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t35.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1162.44s of the 3561.77s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-1.3345\t = Validation score   (-log_loss)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t38.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1123.85s of the 3523.18s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.4394\t = Validation score   (-log_loss)\n",
      "\t61.17s\t = Training   runtime\n",
      "\t21.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1045.31s of the 3444.64s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.4378\t = Validation score   (-log_loss)\n",
      "\t26.39s\t = Training   runtime\n",
      "\t7.59s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1010.22s of the 3409.55s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 251 due to low memory. Expected memory usage reduced from 17.86% -> 15.0% of available memory...\n",
      "\t-0.4495\t = Validation score   (-log_loss)\n",
      "\t29.09s\t = Training   runtime\n",
      "\t7.0s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 973.28s of the 3372.61s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 250 due to low memory. Expected memory usage reduced from 17.96% -> 15.0% of available memory...\n",
      "\t-0.4494\t = Validation score   (-log_loss)\n",
      "\t31.03s\t = Training   runtime\n",
      "\t6.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 934.96s of the 3334.29s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.4376\t = Validation score   (-log_loss)\n",
      "\t281.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 647.22s of the 3046.54s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 274 due to low memory. Expected memory usage reduced from 16.38% -> 15.0% of available memory...\n",
      "\t-0.4478\t = Validation score   (-log_loss)\n",
      "\t18.49s\t = Training   runtime\n",
      "\t6.56s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 621.27s of the 3020.6s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 276 due to low memory. Expected memory usage reduced from 16.27% -> 15.0% of available memory...\n",
      "\t-0.4474\t = Validation score   (-log_loss)\n",
      "\t18.92s\t = Training   runtime\n",
      "\t6.45s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 595.11s of the 2994.44s of remaining time.\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "label = 'Delay'\n",
    "eval_metric = 'log_loss'\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, problem_type='binary', eval_metric=eval_metric\n",
    ").fit(train_data=train_st,\n",
    "      unlabeled_data = X_nan.drop('Delay', axis=1), \n",
    "      presets='best_quality', \n",
    "      num_stack_levels=3,\n",
    "      #excluded_model_types = excluded_model_types,\n",
    "      time_limit=3600, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_Month</th>\n",
       "      <th>Origin_Airport</th>\n",
       "      <th>Origin_State</th>\n",
       "      <th>Destination_Airport</th>\n",
       "      <th>Destination_State</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Carrier_ID(DOT)</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Delay</th>\n",
       "      <th>Estimated_Time</th>\n",
       "      <th>Dep_time_gb</th>\n",
       "      <th>Arr_time_gb</th>\n",
       "      <th>route_gb</th>\n",
       "      <th>edt_h</th>\n",
       "      <th>edt_m</th>\n",
       "      <th>eat_h</th>\n",
       "      <th>eat_m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN_000001</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>331</td>\n",
       "      <td>45</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_000002</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>204</td>\n",
       "      <td>30</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_000003</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>28</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_000004</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>322</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_000007</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>23</td>\n",
       "      <td>403.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_999995</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>270</td>\n",
       "      <td>36</td>\n",
       "      <td>678.0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_999996</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>122</td>\n",
       "      <td>32</td>\n",
       "      <td>242</td>\n",
       "      <td>21</td>\n",
       "      <td>223.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>2293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_999997</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>248</td>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_999998</th>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>214.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_999999</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>307</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714613 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Month  Day_of_Month  Origin_Airport  Origin_State  \\\n",
       "ID                                                                \n",
       "TRAIN_000001      8            15             256            11   \n",
       "TRAIN_000002      9             6              74            31   \n",
       "TRAIN_000003      7            10             195             4   \n",
       "TRAIN_000004      1            11             322             4   \n",
       "TRAIN_000007      4            20             256            11   \n",
       "...             ...           ...             ...           ...   \n",
       "TRAIN_999995      9            18             256            11   \n",
       "TRAIN_999996      5            30             122            32   \n",
       "TRAIN_999997      6            28             248             4   \n",
       "TRAIN_999998      9            27              45            41   \n",
       "TRAIN_999999      3            26             307             7   \n",
       "\n",
       "              Destination_Airport  Destination_State  Distance  Airline  \\\n",
       "ID                                                                        \n",
       "TRAIN_000001                  331                 45    1250.0       22   \n",
       "TRAIN_000002                  204                 30     544.0        3   \n",
       "TRAIN_000003                  119                 28    2454.0       26   \n",
       "TRAIN_000004                    7                  4     250.0       22   \n",
       "TRAIN_000007                  217                 23     403.0       22   \n",
       "...                           ...                ...       ...      ...   \n",
       "TRAIN_999995                  270                 36     678.0       26   \n",
       "TRAIN_999996                  242                 21     223.0       22   \n",
       "TRAIN_999997                  159                 42    1642.0       23   \n",
       "TRAIN_999998                   22                  8     214.0        9   \n",
       "TRAIN_999999                  103                 20    1084.0        9   \n",
       "\n",
       "              Carrier_ID(DOT)  Tail_Number Delay  Estimated_Time  Dep_time_gb  \\\n",
       "ID                                                                              \n",
       "TRAIN_000001               12          310   NaN           164.0            2   \n",
       "TRAIN_000002                4          140   NaN           115.0           11   \n",
       "TRAIN_000003                6         3019   NaN           510.0            4   \n",
       "TRAIN_000004               12          555   NaN            79.0            4   \n",
       "TRAIN_000007               12          173   NaN           100.0           13   \n",
       "...                       ...          ...   ...             ...          ...   \n",
       "TRAIN_999995                6         2476   NaN           187.0            4   \n",
       "TRAIN_999996               12         2293   NaN            68.0            4   \n",
       "TRAIN_999997                0          993   NaN           340.0            3   \n",
       "TRAIN_999998                3         6203   NaN           131.0           11   \n",
       "TRAIN_999999                3         3665   NaN           176.0           13   \n",
       "\n",
       "              Arr_time_gb  route_gb  edt_h  edt_m  eat_h  eat_m  \n",
       "ID                                                               \n",
       "TRAIN_000001            5         1      7     40     10     24  \n",
       "TRAIN_000002           13         2     16     10     18      5  \n",
       "TRAIN_000003           12         1      9      5     17     35  \n",
       "TRAIN_000004            5         2      9      0     10     19  \n",
       "TRAIN_000007           14         2     18     15     19     55  \n",
       "...                   ...       ...    ...    ...    ...    ...  \n",
       "TRAIN_999995            7         2      9     36     12     43  \n",
       "TRAIN_999996            5         2      9     20     10     28  \n",
       "TRAIN_999997            8         1      8      0     13     40  \n",
       "TRAIN_999998           13         2     16     13     18     24  \n",
       "TRAIN_999999           15         1     18      0     20     56  \n",
       "\n",
       "[714613 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_st\n",
    "X_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = train_st\n",
    "y = train_ar[(train_ar['Delay'].astype(str) != 'nan') & (train_ar['route_gb'] != 'long_route')]['Delay']\n",
    "\n",
    "stclf = SelfTrainingClassifier(\n",
    "    base_estimator = RandomForestClassifier(n_estimators = 100),\n",
    "    verbose = True)\n",
    "\n",
    "stclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan['Delay_pred'] = stclf.predict(X_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st.loc[train_st['Delay'] == 'nan', 'Delay'] = X_nan['Delay_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ad6a5e467af0c55cd3439f95cdffc9b087666e3ab0338166755486d36b79e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

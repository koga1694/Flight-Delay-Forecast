{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "data = pd.read_csv('C:/workplace/dacon/airplane/DATA/train.csv')\n",
    "test = pd.read_csv('C:/workplace/dacon/airplane/DATA/test.csv')\n",
    "sub = pd.read_csv('C:/workplace/dacon/airplane/DATA/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_not_delayed_test = test[test['Origin_Airport'].isin(['RIW'])]\n",
    "test = test[~test['Origin_Airport'].isin(['RIW'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "class Processing:\n",
    "    def __init__(self, x, test): # 이후 테스트 데이터도 넣는 버전 만들어야함\n",
    "        self.x = x\n",
    "        self.test = test\n",
    "    \n",
    "    def fill_airline_and_id_2(self, data):\n",
    "        master_dil = 'MASTER2.txt'\n",
    "        df = []\n",
    "        with open(master_dil, 'r', encoding = \"utf-8-sig\") as file:\n",
    "           df.append(file.readlines())\n",
    "           \n",
    "        df = list(itertools.chain(*df))  \n",
    "        df = [line.split(',') for line in df]\n",
    "        col = df[0]\n",
    "        df = pd.DataFrame(df, columns = col)\n",
    "        Airline2 = df[['N-NUMBER', 'NAME']].rename(columns={'N-NUMBER' : 'Tail_Number', 'NAME' : 'NAME2'})\n",
    "        df['Tail_Number'] = ['N' + i for i in df['N-NUMBER']]\n",
    "        Airline = df[['Tail_Number', 'NAME']]\n",
    "\n",
    "        data = pd.merge(data, Airline, left_on = 'Tail_Number', right_on = 'Tail_Number', how = 'left')\n",
    "        ar = pd.merge(data, Airline2, left_on = 'Tail_Number', right_on = 'Tail_Number', how = 'left')\n",
    "        \n",
    "        ar.loc[ar['Tail_Number'] == 'N297AK', 'NAME'] = 'ALASKA AIRLINES INC'\n",
    "        ar.loc[ar['Tail_Number'] == '276NV', 'NAME'] = 'ALLEGIANT AIR LLC'\n",
    "        \n",
    "        ar = ar.fillna('nan')\n",
    "        \n",
    "        # DB-NAME을 Train Airline 기준으로 바꿈\n",
    "        for base in ar.loc[~ar['Airline'].isin(['nan']), 'Airline'].unique():\n",
    "            name1 = ar.loc[(ar['Airline'] == base) & ~(ar['NAME'].isin(['nan'])) & ~(ar['NAME'].isin(ar['Airline'].unique())), 'NAME'].unique()\n",
    "            name2 = ar.loc[(ar['Airline'] == base) & ~(ar['NAME2'].isin(['nan'])) & ~(ar['NAME2'].isin(ar['Airline'].unique())), 'NAME2'].unique()\n",
    "            ar['NAME'].replace(name1, base, inplace=True)\n",
    "            ar['NAME2'].replace(name2, base, inplace=True)\n",
    "        \n",
    "        def apy(x):\n",
    "            if x['NAME'] != 'nan':\n",
    "                x['Airline'] = x['NAME']\n",
    "            elif (x['NAME'] == 'nan') & (x['NAME2'] != 'nan'):\n",
    "                x['Airline'] = x['NAME2']\n",
    "            return x\n",
    "        \n",
    "        ar.loc[ar['Airline'] == 'nan'] = ar.loc[ar['Airline'] == 'nan'].apply(apy, axis=1)\n",
    "        \n",
    "        for n in ar[ar['Airline'] == 'nan']['Tail_Number'].unique():\n",
    "            if ar.loc[ar['Tail_Number'] == n, ['Airline', 'Carrier_ID(DOT)']].shape[0] != ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), ['Airline', 'Carrier_ID(DOT)']].shape[0]:\n",
    "                ar.loc[ar['Tail_Number'] == n, 'Airline'] = ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), 'Airline'].unique()[0]\n",
    "                ar.loc[ar['Tail_Number'] == n, 'Carrier_ID(DOT)'] = ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), 'Carrier_ID(DOT)'].unique()[0]\n",
    "        \n",
    "        ar['Airline'] = ar['Airline'].str.rstrip()\n",
    "        ar['Airline'] = ar['Airline'].str.split('.').str[0]\n",
    "        \n",
    "        # ID 다시채움\n",
    "        for airline in ar['Airline'].unique():\n",
    "            id = ar.loc[(ar['Airline'] == airline) & ~(ar['Carrier_ID(DOT)'].isin(['nan'])), 'Carrier_ID(DOT)'].unique()\n",
    "            ar.loc[ar['Airline'] == airline, 'Carrier_ID(DOT)'] = id[0]\n",
    "        \n",
    "        return ar\n",
    "                \n",
    "    def to_time(self, data, where = None):\n",
    "        if where == None:\n",
    "            print('where 넣어야함')\n",
    "            return None\n",
    "        \n",
    "        def to_time(time_list):\n",
    "            if where == 'first':\n",
    "                Time = pd.Series(time_list).astype(str).str.zfill(4)\n",
    "                Time = Time.replace('2400','0000')\n",
    "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") if i != '0nan' else np.NaN for i in Time]\n",
    "            \n",
    "            elif where == 'twice':\n",
    "                Time = pd.Series(time_list)\n",
    "                Time = Time.replace('2400','0000')\n",
    "                Time = Time.replace('9999','1557')\n",
    "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") for i in Time]  \n",
    "        \n",
    "        def time_gb(x):\n",
    "            if x >= 600 and x <= 659:\n",
    "                return '0600-0659'\n",
    "            elif x>=1400 and x<=1459:\n",
    "                return '1400-1459'\n",
    "            elif x>=1200 and x<=1259:\n",
    "                return '1200-1259'\n",
    "            elif x>=1500 and x<=1559:\n",
    "                return '1500-1559'\n",
    "            elif x>=1900 and x<=1959:\n",
    "                return '1900-1959'\n",
    "            elif x>=900 and x<=959:\n",
    "                return '0900-0959'\n",
    "            elif x>=1000 and x<=1059:\n",
    "                return  '1000-1059'\n",
    "            elif x>=2000 and x<=2059:\n",
    "                return '2000-2059'\n",
    "            elif x>=1300 and x<=1359:\n",
    "                return '1300-1359'\n",
    "            elif x>=1100 and x<=1159:\n",
    "                return '1100-1159'\n",
    "            elif x>=800 and x<=859:\n",
    "                return '0800-0859'\n",
    "            elif x>=2200 and x<=2259:\n",
    "                return '2200-2259'\n",
    "            elif x>=1600 and x<=1659:\n",
    "                return '1600-1659'\n",
    "            elif x>=1700 and x<=1759:\n",
    "                return '1700-1759'\n",
    "            elif x>=2100 and x<=2159:\n",
    "                return '2100-2159'\n",
    "            elif x>=700 and x<=759:\n",
    "                return '0700-0759'\n",
    "            elif x>=1800 and x<=1859:\n",
    "                return '1800-1859'\n",
    "            elif x>=1 and x<=559:\n",
    "                return '0001-0559'\n",
    "            elif x>=2300 and x<=2400:\n",
    "                return '2300-2400'\n",
    "            \n",
    "        def distance_gb(x):\n",
    "            if x < 700 :\n",
    "                return 'short_route'\n",
    "            elif x>=700 and x<3000:\n",
    "                return 'mid_route'\n",
    "            elif x>=3000:\n",
    "                return 'long_route'    \n",
    "        \n",
    "        if where == 'first':\n",
    "            time_list = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Departure_Time'] ]\n",
    "            time_list1 = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Arrival_Time'] ]\n",
    "            \n",
    "        elif where == 'twice':\n",
    "            time_list = [i for i in data['Estimated_Departure_Time']]\n",
    "            time_list1 = [i for i in data['Estimated_Arrival_Time']]\n",
    "        data['Estimated_Departure_Time_HH:MM'] = to_time(time_list)\n",
    "        data['Estimated_Arrival_Time_HH:MM'] = to_time(time_list1)\n",
    "    \n",
    "        \n",
    "        # 예상 비행시간 만들기 (분으로 만들기)\n",
    "        data_est_time = []\n",
    "        for i,j in zip(data['Estimated_Arrival_Time_HH:MM'], data['Estimated_Departure_Time_HH:MM']):\n",
    "            if str(i) != 'nan' and str(j) != 'nan':\n",
    "                if (datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60 >= 0:\n",
    "                    data_est_time.append((datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60)\n",
    "                else:\n",
    "                    time = datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\") + datetime.strptime('23:59', \"%H:%M\") + timedelta(minutes=1)\n",
    "                    data_est_time.append(timedelta(hours=time.hour,minutes=time.minute ).total_seconds()/60)\n",
    "            else:\n",
    "                data_est_time.append(np.NaN)\n",
    "        \n",
    "        if where == 'first':\n",
    "            data['Estimated_Time'] = data_est_time\n",
    "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].dropna().apply(time_gb)\n",
    "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].dropna().apply(time_gb)\n",
    "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
    "            \n",
    "        elif where == 'twice':\n",
    "            data['Estimated_Time'] = data_est_time\n",
    "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].astype(int).apply(time_gb)\n",
    "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].astype(int).apply(time_gb)\n",
    "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def fill_airline_and_id(self, data):\n",
    "        \n",
    "        for airline in data['Airline'].dropna().unique():\n",
    "            id = data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'].dropna().unique()\n",
    "            data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'] = id[0]\n",
    "                \n",
    "\n",
    "        for id in data['Carrier_ID(DOT)'].dropna().unique():\n",
    "            airline = data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'].dropna().unique()\n",
    "            data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'] = airline[0]\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def fill_state(self, data):\n",
    "        for id in data['Origin_Airport_ID'].dropna().unique():\n",
    "            # 테스트셋에 알수없는 Origin State -> dummy로 채움\n",
    "            try:\n",
    "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'].dropna().unique()[0]\n",
    "            except:\n",
    "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = 'dummy'\n",
    "        \n",
    "        for id in data['Destination_Airport_ID'].dropna().unique():\n",
    "            try:\n",
    "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'].dropna().unique()[0]\n",
    "            except: # 기록이 하나밖에 없음. Youngstown (YNG 공항)\n",
    "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = 'Youngstown'\n",
    "        return data\n",
    "        \n",
    "    def fill_timedata(self, data, where=None):\n",
    "        if where == 'at':\n",
    "            time1 = 'Estimated_Departure_Time'\n",
    "            time2 = 'Estimated_Arrival_Time'\n",
    "            \n",
    "        elif where == 'dt':\n",
    "            time1 = 'Estimated_Arrival_Time'\n",
    "            time2 = 'Estimated_Departure_Time'\n",
    "            \n",
    "        elif where == 'both':\n",
    "            b_data = data[(data['Estimated_Arrival_Time'] != 'nan') & (data['Estimated_Departure_Time'] != 'nan')]\n",
    "            b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
    "            b_data = b_data.reset_index()\n",
    "            b_data = b_data.rename(columns={0:'count'})\n",
    "            b_data = b_data.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
    "            b_data = b_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline'], keep='first')\n",
    "\n",
    "            b_data = b_data.set_index(['Origin_Airport', 'Destination_Airport', 'Airline']).drop('count', axis=1)\n",
    "\n",
    "            b = data[(data['Estimated_Arrival_Time'] == 'nan') & (data['Estimated_Departure_Time'] == 'nan')]\n",
    "            b = b.set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "\n",
    "            b[['Estimated_Arrival_Time', 'Estimated_Departure_Time']] = b_data[['Estimated_Arrival_Time', 'Estimated_Departure_Time']]\n",
    "            \n",
    "            return b.reset_index()\n",
    "        \n",
    "        else:\n",
    "            print('Where 값을 채워주세요. at: 도착시간 보간, dt: 출발시간 보간')\n",
    "            return None\n",
    "            \n",
    "            \n",
    "        # 같은 출발/도착시간이 있을 경우 가장 많은 출발/도착시간으로 채움\n",
    "        merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
    "        merge_data = merge_data.reset_index()\n",
    "        merge_data = merge_data.rename(columns={0:'count'})\n",
    "        merge_data = merge_data[(merge_data[time1] != 'nan') & (merge_data[time2] != 'nan')]\n",
    "        merge_data = merge_data.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
    "        merge_data = merge_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline', time1], keep='first')\n",
    "        mt = data.loc[(data[time2].isin(['nan'])) & ~(data[time1].isin(['nan'])), ['Origin_Airport', 'Destination_Airport', 'Airline',time2, time1]]\n",
    "        mt = mt.drop(time2, axis=1)\n",
    "        mt = pd.merge(mt, merge_data, how='left', on =['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
    "        \n",
    "        # 같은 출발/도착시간이 없을 경우 출도착공항, 항공사 기준 Estimated_Time이 가장 많은 시간을 채우고 출발/도착시간을 계산\n",
    "        et = merge_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[['Estimated_Time']].value_counts()\n",
    "        et = et.reset_index()\n",
    "        et = et.rename(columns={0:'count'})\n",
    "        et = et.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
    "        et = et.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline'], keep='first').drop(['count'], axis=1)\n",
    "        mt2 = mt[mt[time2].isna()].drop(['Estimated_Time', 'count'], axis=1)\n",
    "        mt2 = pd.merge(mt2, et, how='left', on =['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "        \n",
    "        # 위 조건에서 Estimated_Time이 없을경우 출도착공항만 고려하여 Estimated_Time이 가장 많은 시간을 채우고 출발/도착시간을 계산\n",
    "        et2 = merge_data.groupby(['Origin_Airport', 'Destination_Airport'])[['Estimated_Time']].value_counts()\n",
    "        et2 = et2.reset_index()\n",
    "        et2 = et2.rename(columns={0:'count'})\n",
    "        et2 = et2.sort_values(['Origin_Airport', 'Destination_Airport', 'count'], ascending=False)\n",
    "        et2 = et2.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport'], keep='first').drop(['count'], axis=1)\n",
    "        mt3= mt2[mt2['Estimated_Time'].isna()].drop(['Estimated_Time'], axis=1)\n",
    "        mt3 = pd.merge(mt3, et2, how='left', on =['Origin_Airport', 'Destination_Airport'])\n",
    "        \n",
    "        # mt3-mt2 합침\n",
    "        mt= mt.set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "        mt2= mt2.set_index(['Origin_Airport', 'Destination_Airport'])\n",
    "        mt3= mt3.set_index(['Origin_Airport', 'Destination_Airport'])\n",
    "        mt2.loc[mt2['Estimated_Time'].isna(), 'Estimated_Time'] = mt3['Estimated_Time']\n",
    "        \n",
    "        # mt2-mt 합침\n",
    "        mt2= mt2.reset_index().set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
    "        mt.loc[mt['Estimated_Time'].isna(), 'Estimated_Time'] = mt2['Estimated_Time']\n",
    "        \n",
    "        # mt-data 합침 (따로 분리하여 나중에 한번에 채움. 보간한 값을 보간할 때 사용하지 않기 위함)\n",
    "        mt = mt.drop('count', axis=1).reset_index().set_index(['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
    "        fill_data = data[(data[time1] != 'nan') & (data[time2] == 'nan')]\n",
    "        fill_data = fill_data.set_index(['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
    "        fill_data[[time2, 'Estimated_Time']] = mt[[time2, 'Estimated_Time']]\n",
    "        fill_data = fill_data.reset_index()\n",
    "        \n",
    "        return fill_data   \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # 시간 채우는 함수\n",
    "    def fill_time(self, data, where = None):\n",
    "        at_data = self.fill_timedata(data, where='at')\n",
    "        dt_data = self.fill_timedata(data, where='dt')\n",
    "        b_data = self.fill_timedata(data, where='both')\n",
    "\n",
    "        data = data.set_index('ID')\n",
    "        at_data = at_data.set_index('ID')\n",
    "        dt_data = dt_data.set_index('ID')\n",
    "        b_data = b_data.set_index('ID')\n",
    "        \n",
    "        data.loc[(data['Estimated_Arrival_Time'] == 'nan') & (data['Estimated_Departure_Time'] != 'nan'), ['Estimated_Arrival_Time', 'Estimated_Time']] = at_data[['Estimated_Arrival_Time', 'Estimated_Time']]\n",
    "        data.loc[(data['Estimated_Departure_Time'] == 'nan')  & (data['Estimated_Arrival_Time'] != 'nan'), ['Estimated_Departure_Time', 'Estimated_Time']] = dt_data[['Estimated_Departure_Time', 'Estimated_Time']]\n",
    "        data.loc[(data['Estimated_Departure_Time'] == 'nan') & (data['Estimated_Arrival_Time'] == 'nan'), ['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']] = b_data[['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']]\n",
    "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].fillna(9999).astype(int).astype(str)\n",
    "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].str.zfill(4)\n",
    "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].fillna(9999).astype(int).astype(str)\n",
    "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].str.zfill(4)\n",
    "        \n",
    "        # apply용 함수\n",
    "        def arr_time(x):\n",
    "            try:\n",
    "                x['Estimated_Departure_Time'] = x['Estimated_Departure_Time'].replace('2400','0000')\n",
    "                time = datetime.strptime(x['Estimated_Departure_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
    "                hour = str(time.hour)\n",
    "                minute = str(time.minute)\n",
    "                x['Estimated_Arrival_Time'] = hour+minute       \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def dep_time(x):\n",
    "            try:\n",
    "                x['Estimated_Arrival_Time'] = x['Estimated_Arrival_Time'].replace('2400','0000')\n",
    "                time = datetime.strptime(x['Estimated_Arrival_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
    "                hour = str(time.hour)\n",
    "                minute = str(time.minute)\n",
    "                x['Estimated_Departure_Time'] = hour+minute       \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        add_time = data.loc[(data['Estimated_Arrival_Time'] == '9999') & (data['Estimated_Departure_Time'] != '9999'), ['Estimated_Departure_Time', 'Estimated_Time', 'Estimated_Arrival_Time']]\n",
    "        t = add_time.apply(arr_time, axis=1)\n",
    "        t= t[~t['Estimated_Time'].isna()]\n",
    "        data.loc[t.index, 'Estimated_Arrival_Time'] = t['Estimated_Arrival_Time']\n",
    "        \n",
    "        add_time = data.loc[(data['Estimated_Arrival_Time'] != '9999') & (data['Estimated_Departure_Time'] == '9999'), ['Estimated_Arrival_Time', 'Estimated_Time', 'Estimated_Departure_Time']]\n",
    "        t = add_time.apply(dep_time, axis=1)\n",
    "        t= t[~t['Estimated_Time'].isna()]\n",
    "        data.loc[t.index, 'Estimated_Departure_Time'] = t['Estimated_Departure_Time']\n",
    "        \n",
    "        if where == 'test':\n",
    "            test = data[~data['Estimated_Time'].isna()]\n",
    "            test = data[data['Estimated_Time'] != 'nan']\n",
    "            \n",
    "            return test, data\n",
    "            \n",
    "\n",
    "        data = data[~data['Estimated_Time'].isna()]\n",
    "        data = data[data['Estimated_Time'] != 'nan']\n",
    "\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def train_processing(self):\n",
    "        data = self.fill_airline_and_id(self.x)\n",
    "        data = self.fill_state(data)\n",
    "        data = self.to_time(data, where='first')\n",
    "        data = self.fill_airline_and_id_2(data)\n",
    "        data = self.fill_time(data)\n",
    "        data = self.to_time(data, where='twice')\n",
    "        \n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def test_processing(self):\n",
    "        data = self.fill_airline_and_id(self.test)\n",
    "        data = self.fill_state(data)\n",
    "        data = self.to_time(data, where='first')\n",
    "        data = self.fill_airline_and_id_2(data)\n",
    "        data, origin = self.fill_time(data, where='test')\n",
    "        data = self.to_time(data, where='twice')\n",
    "        \n",
    "    \n",
    "        return data, origin\n",
    "                \n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:205: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
      "C:\\Users\\kweon\\AppData\\Local\\Temp\\ipykernel_11688\\3432667170.py:205: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n"
     ]
    }
   ],
   "source": [
    "pc = Processing(data, test)\n",
    "\n",
    "train = pc.train_processing()\n",
    "test, origin_test = pc.test_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[~test['Estimated_Departure_Time'].isin(['1557'])]\n",
    "test = test[~test['Estimated_Arrival_Time'].isin(['1557'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE(x):\n",
    "    x = x.drop(['NAME','NAME2', 'Carrier_Code(IATA)', 'Cancelled', 'Diverted', 'Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
    "    x['edt_h'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
    "    x['edt_m'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
    "    x['eat_h'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
    "    x['eat_m'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
    "\n",
    "    x = x.drop(['Estimated_Departure_Time_HH:MM', 'Estimated_Arrival_Time_HH:MM'], axis=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "train = FE(train)\n",
    "test = FE(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'SHR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SHR'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m train_st[i]\u001b[39m=\u001b[39mle\u001b[39m.\u001b[39mtransform(train_st[i])\n\u001b[0;32m     15\u001b[0m X_nan[i]\u001b[39m=\u001b[39mle\u001b[39m.\u001b[39mtransform(X_nan[i])\n\u001b[1;32m---> 16\u001b[0m test_ar[i]\u001b[39m=\u001b[39mle\u001b[39m.\u001b[39;49mtransform(test_ar[i])\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[1;32mc:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'SHR'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_ar = train.__deepcopy__()\n",
    "test_ar = test.__deepcopy__()\n",
    "\n",
    "label_st = train_ar.drop(columns = ['Delay'])\n",
    "train_st = train_ar[(train_ar['Delay'].astype(str) != 'nan') & (train_ar['route_gb'] != 'long_route')].drop(columns = ['Delay'])\n",
    "X_nan = train_ar[(train_ar['Delay'].astype(str) == 'nan')& (train_ar['route_gb'] != 'long_route')].drop(columns = ['Delay'])\n",
    "\n",
    "qual_col = ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline', 'Carrier_ID(DOT)', 'Tail_Number', 'Dep_time_gb',\t'Arr_time_gb',\t'route_gb']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(label_st[i])\n",
    "    train_st[i]=le.transform(train_st[i])\n",
    "    X_nan[i]=le.transform(X_nan[i])\n",
    "    test_ar[i]=le.transform(test_ar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kweon\\anaconda3\\envs\\gibo\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:212: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelfTrainingClassifier</label><div class=\"sk-toggleable__content\"><pre>SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = train_st\n",
    "y = train_ar[(train_ar['Delay'].astype(str) != 'nan') & (train_ar['route_gb'] != 'long_route')]['Delay']\n",
    "\n",
    "stclf = SelfTrainingClassifier(\n",
    "    base_estimator = RandomForestClassifier(n_estimators = 100),\n",
    "    verbose = True)\n",
    "\n",
    "stclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan['Delay_pred'] = stclf.predict(X_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_Month</th>\n",
       "      <th>Origin_Airport</th>\n",
       "      <th>Origin_Airport_ID</th>\n",
       "      <th>Origin_State</th>\n",
       "      <th>Destination_Airport</th>\n",
       "      <th>Destination_Airport_ID</th>\n",
       "      <th>Destination_State</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Carrier_ID(DOT)</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Estimated_Time</th>\n",
       "      <th>Dep_time_gb</th>\n",
       "      <th>Arr_time_gb</th>\n",
       "      <th>route_gb</th>\n",
       "      <th>edt_h</th>\n",
       "      <th>edt_m</th>\n",
       "      <th>eat_h</th>\n",
       "      <th>eat_m</th>\n",
       "      <th>Delay_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>13930</td>\n",
       "      <td>11</td>\n",
       "      <td>331</td>\n",
       "      <td>14869</td>\n",
       "      <td>45</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>310</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>11057</td>\n",
       "      <td>31</td>\n",
       "      <td>204</td>\n",
       "      <td>12953</td>\n",
       "      <td>30</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>115.0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>195</td>\n",
       "      <td>12892</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>11618</td>\n",
       "      <td>28</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3019</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>322</td>\n",
       "      <td>14771</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10157</td>\n",
       "      <td>4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>555</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>13930</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>13198</td>\n",
       "      <td>23</td>\n",
       "      <td>403.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988273</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>256</td>\n",
       "      <td>13930</td>\n",
       "      <td>11</td>\n",
       "      <td>270</td>\n",
       "      <td>14100</td>\n",
       "      <td>36</td>\n",
       "      <td>678.0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2476</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988274</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>122</td>\n",
       "      <td>11637</td>\n",
       "      <td>32</td>\n",
       "      <td>242</td>\n",
       "      <td>13487</td>\n",
       "      <td>21</td>\n",
       "      <td>223.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>2293</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988275</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>248</td>\n",
       "      <td>13796</td>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>12191</td>\n",
       "      <td>42</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>993</td>\n",
       "      <td>340.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988276</th>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "      <td>10693</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>10397</td>\n",
       "      <td>8</td>\n",
       "      <td>214.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6205</td>\n",
       "      <td>131.0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988277</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>307</td>\n",
       "      <td>14635</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "      <td>11433</td>\n",
       "      <td>20</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3665</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>56</td>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735159 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  Day_of_Month  Origin_Airport  Origin_Airport_ID  Origin_State  \\\n",
       "0           8            15             256              13930            11   \n",
       "1           9             6              74              11057            31   \n",
       "2           7            10             195              12892             4   \n",
       "3           1            11             322              14771             4   \n",
       "6           4            20             256              13930            11   \n",
       "...       ...           ...             ...                ...           ...   \n",
       "988273      9            18             256              13930            11   \n",
       "988274      5            30             122              11637            32   \n",
       "988275      6            28             248              13796             4   \n",
       "988276      9            27              45              10693            41   \n",
       "988277      3            26             307              14635             7   \n",
       "\n",
       "        Destination_Airport  Destination_Airport_ID  Destination_State  \\\n",
       "0                       331                   14869                 45   \n",
       "1                       204                   12953                 30   \n",
       "2                       119                   11618                 28   \n",
       "3                         7                   10157                  4   \n",
       "6                       217                   13198                 23   \n",
       "...                     ...                     ...                ...   \n",
       "988273                  270                   14100                 36   \n",
       "988274                  242                   13487                 21   \n",
       "988275                  159                   12191                 42   \n",
       "988276                   22                   10397                  8   \n",
       "988277                  103                   11433                 20   \n",
       "\n",
       "        Distance  Airline  Carrier_ID(DOT)  Tail_Number  Estimated_Time  \\\n",
       "0         1250.0       22               12          310           164.0   \n",
       "1          544.0        3                4          140           115.0   \n",
       "2         2454.0       26                6         3019           510.0   \n",
       "3          250.0       22               12          555            79.0   \n",
       "6          403.0       22               12          173           100.0   \n",
       "...          ...      ...              ...          ...             ...   \n",
       "988273     678.0       26                6         2476           187.0   \n",
       "988274     223.0       22               12         2293            68.0   \n",
       "988275    1642.0       23                0          993           340.0   \n",
       "988276     214.0        9                3         6205           131.0   \n",
       "988277    1084.0        9                3         3665           176.0   \n",
       "\n",
       "        Dep_time_gb  Arr_time_gb  route_gb  edt_h  edt_m  eat_h  eat_m  \\\n",
       "0                 2            5         1      7     40     10     24   \n",
       "1                11           13         2     16     10     18      5   \n",
       "2                 4           12         1      9      5     17     35   \n",
       "3                 4            5         2      9      0     10     19   \n",
       "6                13           14         2     18     15     19     55   \n",
       "...             ...          ...       ...    ...    ...    ...    ...   \n",
       "988273            4            7         2      9     36     12     43   \n",
       "988274            4            5         2      9     20     10     28   \n",
       "988275            3            8         1      8      0     13     40   \n",
       "988276           11           13         2     16     13     18     24   \n",
       "988277           13           15         1     18      0     20     56   \n",
       "\n",
       "         Delay_pred  \n",
       "0       Not_Delayed  \n",
       "1       Not_Delayed  \n",
       "2       Not_Delayed  \n",
       "3       Not_Delayed  \n",
       "6       Not_Delayed  \n",
       "...             ...  \n",
       "988273  Not_Delayed  \n",
       "988274  Not_Delayed  \n",
       "988275  Not_Delayed  \n",
       "988276  Not_Delayed  \n",
       "988277  Not_Delayed  \n",
       "\n",
       "[735159 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_st.loc[train_st['Delay'] == 'nan', 'Delay'] = X_nan['Delay_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "automl = AutoML(mode=\"Compete\", eval_metric='f1', \n",
    "                total_time_limit=None, algorithms=['LightGBM', 'Xgboost', 'CatBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(x = train_st.drop('Delay', axis=1), y= train_st['Delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = automl.predict_proba(test_ar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ad6a5e467af0c55cd3439f95cdffc9b087666e3ab0338166755486d36b79e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

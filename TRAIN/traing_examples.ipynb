{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnLs4PCa1qcx",
        "outputId": "5012a33a-2b18-4251-e0d1-6eeaa48c2ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = '/content/drive/MyDrive/데이콘/데이콘 항공편 지연/데이콘_항공편_지연'"
      ],
      "metadata": {
        "id": "AbYT-RNS24GX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Ktj9lZBL23-w"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "gJxBVEVj238X"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_parquet(csv_path, save_name):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.to_parquet(f'./{save_name}.parquet')\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(save_name, 'Done.')"
      ],
      "metadata": {
        "id": "PUqFK0_72665"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_to_parquet(file_dir + '/train.csv', 'train')\n",
        "csv_to_parquet(file_dir + '/test.csv', 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3uFu_e328n9",
        "outputId": "0dfb6709-bb33-4ed3-f35d-50ea26c0301a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Done.\n",
            "test Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/train.parquet')\n",
        "test = pd.read_parquet('/content/test.parquet')\n",
        "sample_submission = pd.read_csv(file_dir+'/sample_submission.csv', index_col = 0)"
      ],
      "metadata": {
        "id": "Q7Au_V2k290P"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "NOef7PTG1qc0"
      },
      "outputs": [],
      "source": [
        "after_not_delayed_test = test[test['Origin_Airport'].isin(['RIW'])]\n",
        "test = test[~test['Origin_Airport'].isin(['RIW'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOntMDup1qc0"
      },
      "source": [
        "# 데이터 전처리 파이프라인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "AK5PHOQo1qc2"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime, timedelta\n",
        "pd.set_option('mode.chained_assignment',  None)\n",
        "class Processing:\n",
        "    def __init__(self, x, test): # 이후 테스트 데이터도 넣는 버전 만들어야함\n",
        "        self.x = x\n",
        "        self.test = test\n",
        "    \n",
        "    def fill_airline_and_id_2(self, data):\n",
        "        master_dil = '/content/drive/MyDrive/데이콘/데이콘 항공편 지연/데이콘_항공편_지연/ReleasableAircraft.2019/MASTER.txt'\n",
        "        df = []\n",
        "        with open(master_dil, 'r', encoding = \"utf-8-sig\") as file:\n",
        "           df.append(file.readlines())\n",
        "           \n",
        "        df = list(itertools.chain(*df))  \n",
        "        df = [line.split(',') for line in df]\n",
        "        col = df[0]\n",
        "        df = pd.DataFrame(df, columns = col)\n",
        "        Airline2 = df[['N-NUMBER', 'NAME']].rename(columns={'N-NUMBER' : 'Tail_Number', 'NAME' : 'NAME2'})\n",
        "        df['Tail_Number'] = ['N' + i for i in df['N-NUMBER']]\n",
        "        Airline = df[['Tail_Number', 'NAME']]\n",
        "\n",
        "        data = pd.merge(data, Airline, left_on = 'Tail_Number', right_on = 'Tail_Number', how = 'left')\n",
        "        ar = pd.merge(data, Airline2, left_on = 'Tail_Number', right_on = 'Tail_Number', how = 'left')\n",
        "        \n",
        "        ar.loc[ar['Tail_Number'] == 'N297AK', 'NAME'] = 'ALASKA AIRLINES INC'\n",
        "        ar.loc[ar['Tail_Number'] == '276NV', 'NAME'] = 'ALLEGIANT AIR LLC'\n",
        "        \n",
        "        ar = ar.fillna('nan')\n",
        "        \n",
        "        # DB-NAME을 Train Airline 기준으로 바꿈\n",
        "        for base in ar.loc[~ar['Airline'].isin(['nan']), 'Airline'].unique():\n",
        "            name1 = ar.loc[(ar['Airline'] == base) & ~(ar['NAME'].isin(['nan'])) & ~(ar['NAME'].isin(ar['Airline'].unique())), 'NAME'].unique()\n",
        "            name2 = ar.loc[(ar['Airline'] == base) & ~(ar['NAME2'].isin(['nan'])) & ~(ar['NAME2'].isin(ar['Airline'].unique())), 'NAME2'].unique()\n",
        "            ar['NAME'].replace(name1, base, inplace=True)\n",
        "            ar['NAME2'].replace(name2, base, inplace=True)\n",
        "        \n",
        "        def apy(x):\n",
        "            if x['NAME'] != 'nan':\n",
        "                x['Airline'] = x['NAME']\n",
        "            elif (x['NAME'] == 'nan') & (x['NAME2'] != 'nan'):\n",
        "                x['Airline'] = x['NAME2']\n",
        "            return x\n",
        "        \n",
        "        ar.loc[ar['Airline'] == 'nan'] = ar.loc[ar['Airline'] == 'nan'].apply(apy, axis=1)\n",
        "        \n",
        "        for n in ar[ar['Airline'] == 'nan']['Tail_Number'].unique():\n",
        "            if ar.loc[ar['Tail_Number'] == n, ['Airline', 'Carrier_ID(DOT)']].shape[0] != ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), ['Airline', 'Carrier_ID(DOT)']].shape[0]:\n",
        "                ar.loc[ar['Tail_Number'] == n, 'Airline'] = ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), 'Airline'].unique()[0]\n",
        "                ar.loc[ar['Tail_Number'] == n, 'Carrier_ID(DOT)'] = ar.loc[(ar['Tail_Number'] == n) & ~(ar['Airline'].isin(['nan'])), 'Carrier_ID(DOT)'].unique()[0]\n",
        "        \n",
        "        ar['Airline'] = ar['Airline'].str.rstrip()\n",
        "        ar['Airline'] = ar['Airline'].str.split('.').str[0]\n",
        "        \n",
        "        # ID 다시채움\n",
        "        for airline in ar['Airline'].unique():\n",
        "            id = ar.loc[(ar['Airline'] == airline) & ~(ar['Carrier_ID(DOT)'].isin(['nan'])), 'Carrier_ID(DOT)'].unique()\n",
        "            ar.loc[ar['Airline'] == airline, 'Carrier_ID(DOT)'] = id[0]\n",
        "        \n",
        "        return ar\n",
        "                \n",
        "    def to_time(self, data, where = None):\n",
        "        if where == None:\n",
        "            print('where 넣어야함')\n",
        "            return None\n",
        "        \n",
        "        def to_time(time_list):\n",
        "            if where == 'first':\n",
        "                Time = pd.Series(time_list).astype(str).str.zfill(4)\n",
        "                Time = Time.replace('2400','0000')\n",
        "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") if i != '0nan' else np.NaN for i in Time]\n",
        "            \n",
        "            elif where == 'twice':\n",
        "                Time = pd.Series(time_list)\n",
        "                Time = Time.replace('2400','0000')\n",
        "                Time = Time.replace('9999','1557')\n",
        "                return [datetime.strptime(i, '%H%M').strftime(\"%H:%M\") for i in Time]  \n",
        "        \n",
        "        def time_gb(x):\n",
        "            if x >= 600 and x <= 659:\n",
        "                return '0600-0659'\n",
        "            elif x>=1400 and x<=1459:\n",
        "                return '1400-1459'\n",
        "            elif x>=1200 and x<=1259:\n",
        "                return '1200-1259'\n",
        "            elif x>=1500 and x<=1559:\n",
        "                return '1500-1559'\n",
        "            elif x>=1900 and x<=1959:\n",
        "                return '1900-1959'\n",
        "            elif x>=900 and x<=959:\n",
        "                return '0900-0959'\n",
        "            elif x>=1000 and x<=1059:\n",
        "                return  '1000-1059'\n",
        "            elif x>=2000 and x<=2059:\n",
        "                return '2000-2059'\n",
        "            elif x>=1300 and x<=1359:\n",
        "                return '1300-1359'\n",
        "            elif x>=1100 and x<=1159:\n",
        "                return '1100-1159'\n",
        "            elif x>=800 and x<=859:\n",
        "                return '0800-0859'\n",
        "            elif x>=2200 and x<=2259:\n",
        "                return '2200-2259'\n",
        "            elif x>=1600 and x<=1659:\n",
        "                return '1600-1659'\n",
        "            elif x>=1700 and x<=1759:\n",
        "                return '1700-1759'\n",
        "            elif x>=2100 and x<=2159:\n",
        "                return '2100-2159'\n",
        "            elif x>=700 and x<=759:\n",
        "                return '0700-0759'\n",
        "            elif x>=1800 and x<=1859:\n",
        "                return '1800-1859'\n",
        "            elif x>=1 and x<=559:\n",
        "                return '0001-0559'\n",
        "            elif x>=2300 and x<=2400:\n",
        "                return '2300-2400'\n",
        "            \n",
        "        def distance_gb(x):\n",
        "            if x < 700 :\n",
        "                return 'short_route'\n",
        "            elif x>=700 and x<3000:\n",
        "                return 'mid_route'\n",
        "            elif x>=3000:\n",
        "                return 'long_route'    \n",
        "        \n",
        "        if where == 'first':\n",
        "            time_list = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Departure_Time'] ]\n",
        "            time_list1 = [i if str(i) == 'nan' else str(int(i))  for i in data['Estimated_Arrival_Time'] ]\n",
        "            \n",
        "        elif where == 'twice':\n",
        "            time_list = [i for i in data['Estimated_Departure_Time']]\n",
        "            time_list1 = [i for i in data['Estimated_Arrival_Time']]\n",
        "        data['Estimated_Departure_Time_HH:MM'] = to_time(time_list)\n",
        "        data['Estimated_Arrival_Time_HH:MM'] = to_time(time_list1)\n",
        "    \n",
        "        \n",
        "        # 예상 비행시간 만들기 (분으로 만들기)\n",
        "        data_est_time = []\n",
        "        for i,j in zip(data['Estimated_Arrival_Time_HH:MM'], data['Estimated_Departure_Time_HH:MM']):\n",
        "            if str(i) != 'nan' and str(j) != 'nan':\n",
        "                if (datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60 >= 0:\n",
        "                    data_est_time.append((datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\")).total_seconds()/60)\n",
        "                else:\n",
        "                    time = datetime.strptime(str(i), \"%H:%M\") - datetime.strptime(str(j), \"%H:%M\") + datetime.strptime('23:59', \"%H:%M\") + timedelta(minutes=1)\n",
        "                    data_est_time.append(timedelta(hours=time.hour,minutes=time.minute ).total_seconds()/60)\n",
        "            else:\n",
        "                data_est_time.append(np.NaN)\n",
        "        \n",
        "        if where == 'first':\n",
        "            data['Estimated_Time'] = data_est_time\n",
        "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].dropna().apply(time_gb)\n",
        "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].dropna().apply(time_gb)\n",
        "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
        "            \n",
        "        elif where == 'twice':\n",
        "            data['Estimated_Time'] = data_est_time\n",
        "            data['Dep_time_gb'] = data['Estimated_Departure_Time'].astype(int).apply(time_gb)\n",
        "            data['Arr_time_gb'] = data['Estimated_Arrival_Time'].astype(int).apply(time_gb)\n",
        "            data['route_gb'] = data['Distance'].apply(distance_gb)\n",
        "        \n",
        "        return data\n",
        "        \n",
        "    \n",
        "    def fill_airline_and_id(self, data):\n",
        "        \n",
        "        for airline in data['Airline'].dropna().unique():\n",
        "            id = data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'].dropna().unique()\n",
        "            data.loc[data['Airline'] == airline, 'Carrier_ID(DOT)'] = id[0]\n",
        "                \n",
        "\n",
        "        for id in data['Carrier_ID(DOT)'].dropna().unique():\n",
        "            airline = data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'].dropna().unique()\n",
        "            data.loc[data['Carrier_ID(DOT)'] == id, 'Airline'] = airline[0]\n",
        "            \n",
        "        return data\n",
        "    \n",
        "    def fill_state(self, data):\n",
        "        for id in data['Origin_Airport_ID'].dropna().unique():\n",
        "            # 테스트셋에 알수없는 Origin State -> dummy로 채움\n",
        "            try:\n",
        "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'].dropna().unique()[0]\n",
        "            except:\n",
        "                data.loc[data['Origin_Airport_ID'] == id, 'Origin_State'] = 'dummy'\n",
        "        \n",
        "        for id in data['Destination_Airport_ID'].dropna().unique():\n",
        "            try:\n",
        "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'].dropna().unique()[0]\n",
        "            except: # 기록이 하나밖에 없음. Youngstown (YNG 공항)\n",
        "                data.loc[data['Destination_Airport_ID'] == id, 'Destination_State'] = 'Youngstown'\n",
        "        return data\n",
        "        \n",
        "    def fill_timedata(self, data, where=None):\n",
        "        if where == 'at':\n",
        "            time1 = 'Estimated_Departure_Time'\n",
        "            time2 = 'Estimated_Arrival_Time'\n",
        "            \n",
        "        elif where == 'dt':\n",
        "            time1 = 'Estimated_Arrival_Time'\n",
        "            time2 = 'Estimated_Departure_Time'\n",
        "            \n",
        "        elif where == 'both':\n",
        "            b_data = data[(data['Estimated_Arrival_Time'] != 'nan') & (data['Estimated_Departure_Time'] != 'nan')]\n",
        "            b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
        "            b_data = b_data.reset_index()\n",
        "            b_data = b_data.rename(columns={0:'count'})\n",
        "            b_data = b_data.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
        "            b_data = b_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline'], keep='first')\n",
        "\n",
        "            b_data = b_data.set_index(['Origin_Airport', 'Destination_Airport', 'Airline']).drop('count', axis=1)\n",
        "\n",
        "            b = data[(data['Estimated_Arrival_Time'] == 'nan') & (data['Estimated_Departure_Time'] == 'nan')]\n",
        "            b = b.set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
        "\n",
        "            b[['Estimated_Arrival_Time', 'Estimated_Departure_Time']] = b_data[['Estimated_Arrival_Time', 'Estimated_Departure_Time']]\n",
        "            \n",
        "            return b.reset_index()\n",
        "        \n",
        "        else:\n",
        "            print('Where 값을 채워주세요. at: 도착시간 보간, dt: 출발시간 보간')\n",
        "            return None\n",
        "            \n",
        "            \n",
        "        # 같은 출발/도착시간이 있을 경우 가장 많은 출발/도착시간으로 채움\n",
        "        merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
        "        merge_data = merge_data.reset_index()\n",
        "        merge_data = merge_data.rename(columns={0:'count'})\n",
        "        merge_data = merge_data[(merge_data[time1] != 'nan') & (merge_data[time2] != 'nan')]\n",
        "        merge_data = merge_data.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
        "        merge_data = merge_data.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline', time1], keep='first')\n",
        "        mt = data.loc[(data[time2].isin(['nan'])) & ~(data[time1].isin(['nan'])), ['Origin_Airport', 'Destination_Airport', 'Airline',time2, time1]]\n",
        "        mt = mt.drop(time2, axis=1)\n",
        "        mt = pd.merge(mt, merge_data, how='left', on =['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
        "        \n",
        "        # 같은 출발/도착시간이 없을 경우 출도착공항, 항공사 기준 Estimated_Time이 가장 많은 시간을 채우고 출발/도착시간을 계산\n",
        "        et = merge_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[['Estimated_Time']].value_counts()\n",
        "        et = et.reset_index()\n",
        "        et = et.rename(columns={0:'count'})\n",
        "        et = et.sort_values(['Origin_Airport', 'Destination_Airport', 'Airline', 'count'], ascending=False)\n",
        "        et = et.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport', 'Airline'], keep='first').drop(['count'], axis=1)\n",
        "        mt2 = mt[mt[time2].isna()].drop(['Estimated_Time', 'count'], axis=1)\n",
        "        mt2 = pd.merge(mt2, et, how='left', on =['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
        "        \n",
        "        # 위 조건에서 Estimated_Time이 없을경우 출도착공항만 고려하여 Estimated_Time이 가장 많은 시간을 채우고 출발/도착시간을 계산\n",
        "        et2 = merge_data.groupby(['Origin_Airport', 'Destination_Airport'])[['Estimated_Time']].value_counts()\n",
        "        et2 = et2.reset_index()\n",
        "        et2 = et2.rename(columns={0:'count'})\n",
        "        et2 = et2.sort_values(['Origin_Airport', 'Destination_Airport', 'count'], ascending=False)\n",
        "        et2 = et2.drop_duplicates(subset=['Origin_Airport', 'Destination_Airport'], keep='first').drop(['count'], axis=1)\n",
        "        mt3= mt2[mt2['Estimated_Time'].isna()].drop(['Estimated_Time'], axis=1)\n",
        "        mt3 = pd.merge(mt3, et2, how='left', on =['Origin_Airport', 'Destination_Airport'])\n",
        "        \n",
        "        # mt3-mt2 합침\n",
        "        mt= mt.set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
        "        mt2= mt2.set_index(['Origin_Airport', 'Destination_Airport'])\n",
        "        mt3= mt3.set_index(['Origin_Airport', 'Destination_Airport'])\n",
        "        mt2.loc[mt2['Estimated_Time'].isna(), 'Estimated_Time'] = mt3['Estimated_Time']\n",
        "        \n",
        "        # mt2-mt 합침\n",
        "        mt2= mt2.reset_index().set_index(['Origin_Airport', 'Destination_Airport', 'Airline'])\n",
        "        mt.loc[mt['Estimated_Time'].isna(), 'Estimated_Time'] = mt2['Estimated_Time']\n",
        "        \n",
        "        # mt-data 합침 (따로 분리하여 나중에 한번에 채움. 보간한 값을 보간할 때 사용하지 않기 위함)\n",
        "        mt = mt.drop('count', axis=1).reset_index().set_index(['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
        "        fill_data = data[(data[time1] != 'nan') & (data[time2] == 'nan')]\n",
        "        fill_data = fill_data.set_index(['Origin_Airport', 'Destination_Airport', 'Airline', time1])\n",
        "        fill_data[[time2, 'Estimated_Time']] = mt[[time2, 'Estimated_Time']]\n",
        "        fill_data = fill_data.reset_index()\n",
        "        \n",
        "        return fill_data   \n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    # 시간 채우는 함수\n",
        "    def fill_time(self, data, where = None):\n",
        "        at_data = self.fill_timedata(data, where='at')\n",
        "        dt_data = self.fill_timedata(data, where='dt')\n",
        "        b_data = self.fill_timedata(data, where='both')\n",
        "\n",
        "        data = data.set_index('ID')\n",
        "        at_data = at_data.set_index('ID')\n",
        "        dt_data = dt_data.set_index('ID')\n",
        "        b_data = b_data.set_index('ID')\n",
        "        \n",
        "        data.loc[(data['Estimated_Arrival_Time'] == 'nan') & (data['Estimated_Departure_Time'] != 'nan'), ['Estimated_Arrival_Time', 'Estimated_Time']] = at_data[['Estimated_Arrival_Time', 'Estimated_Time']]\n",
        "        data.loc[(data['Estimated_Departure_Time'] == 'nan')  & (data['Estimated_Arrival_Time'] != 'nan'), ['Estimated_Departure_Time', 'Estimated_Time']] = dt_data[['Estimated_Departure_Time', 'Estimated_Time']]\n",
        "        data.loc[(data['Estimated_Departure_Time'] == 'nan') & (data['Estimated_Arrival_Time'] == 'nan'), ['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']] = b_data[['Estimated_Departure_Time', 'Estimated_Arrival_Time', 'Estimated_Time']]\n",
        "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].fillna(9999).astype(int).astype(str)\n",
        "        data['Estimated_Departure_Time'] = data['Estimated_Departure_Time'].str.zfill(4)\n",
        "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].fillna(9999).astype(int).astype(str)\n",
        "        data['Estimated_Arrival_Time'] = data['Estimated_Arrival_Time'].str.zfill(4)\n",
        "        \n",
        "        # apply용 함수\n",
        "        def arr_time(x):\n",
        "            try:\n",
        "                x['Estimated_Departure_Time'] = x['Estimated_Departure_Time'].replace('2400','0000')\n",
        "                time = datetime.strptime(x['Estimated_Departure_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
        "                hour = str(time.hour)\n",
        "                minute = str(time.minute)\n",
        "                x['Estimated_Arrival_Time'] = hour+minute       \n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            return x\n",
        "        \n",
        "        def dep_time(x):\n",
        "            try:\n",
        "                x['Estimated_Arrival_Time'] = x['Estimated_Arrival_Time'].replace('2400','0000')\n",
        "                time = datetime.strptime(x['Estimated_Arrival_Time'], \"%H%M\") + timedelta(minutes=x['Estimated_Time'])\n",
        "                hour = str(time.hour)\n",
        "                minute = str(time.minute)\n",
        "                x['Estimated_Departure_Time'] = hour+minute       \n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            return x\n",
        "        \n",
        "        add_time = data.loc[(data['Estimated_Arrival_Time'] == '9999') & (data['Estimated_Departure_Time'] != '9999'), ['Estimated_Departure_Time', 'Estimated_Time', 'Estimated_Arrival_Time']]\n",
        "        t = add_time.apply(arr_time, axis=1)\n",
        "        t= t[~t['Estimated_Time'].isna()]\n",
        "        data.loc[t.index, 'Estimated_Arrival_Time'] = t['Estimated_Arrival_Time']\n",
        "        \n",
        "        add_time = data.loc[(data['Estimated_Arrival_Time'] != '9999') & (data['Estimated_Departure_Time'] == '9999'), ['Estimated_Arrival_Time', 'Estimated_Time', 'Estimated_Departure_Time']]\n",
        "        t = add_time.apply(dep_time, axis=1)\n",
        "        t= t[~t['Estimated_Time'].isna()]\n",
        "        data.loc[t.index, 'Estimated_Departure_Time'] = t['Estimated_Departure_Time']\n",
        "        \n",
        "        if where == 'test':\n",
        "            test = data[~data['Estimated_Time'].isna()]\n",
        "            test = data[data['Estimated_Time'] != 'nan']\n",
        "            \n",
        "            return test, data\n",
        "            \n",
        "\n",
        "        data = data[~data['Estimated_Time'].isna()]\n",
        "        data = data[data['Estimated_Time'] != 'nan']\n",
        "\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def train_processing(self):\n",
        "        data = self.fill_airline_and_id(self.x)\n",
        "        data = self.fill_state(data)\n",
        "        data = self.to_time(data, where='first')\n",
        "        data = self.fill_airline_and_id_2(data)\n",
        "        data = self.fill_time(data)\n",
        "        data = self.to_time(data, where='twice')\n",
        "        \n",
        "        \n",
        "        return data\n",
        "    \n",
        "    \n",
        "    def test_processing(self):\n",
        "        data = self.fill_airline_and_id(self.test)\n",
        "        data = self.fill_state(data)\n",
        "        data = self.to_time(data, where='first')\n",
        "        data = self.fill_airline_and_id_2(data)\n",
        "        data, origin = self.fill_time(data, where='test')\n",
        "        data = self.to_time(data, where='twice')\n",
        "        \n",
        "    \n",
        "        return data, origin\n",
        "                \n",
        "                \n",
        "            \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY7e3TFf1qc5",
        "outputId": "a6c08081-7b42-41c1-9743-07ddfadbef6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-87-d06091b4e9a9>:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
            "<ipython-input-87-d06091b4e9a9>:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
            "<ipython-input-87-d06091b4e9a9>:205: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n",
            "<ipython-input-87-d06091b4e9a9>:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
            "<ipython-input-87-d06091b4e9a9>:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  merge_data = data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])[time2, time1, 'Estimated_Time'].value_counts()\n",
            "<ipython-input-87-d06091b4e9a9>:205: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  b_data = b_data.groupby(['Origin_Airport', 'Destination_Airport', 'Airline'])['Estimated_Arrival_Time', 'Estimated_Departure_Time'].value_counts()\n"
          ]
        }
      ],
      "source": [
        "pc = Processing(train, test)\n",
        "\n",
        "train = pc.train_processing()\n",
        "test, origin_test = pc.test_processing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "z05Q2sUf1qc6"
      },
      "outputs": [],
      "source": [
        "test = test[~test['Estimated_Departure_Time'].isin(['1557'])]\n",
        "test = test[~test['Estimated_Arrival_Time'].isin(['1557'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "snEKYdBz1qc6"
      },
      "outputs": [],
      "source": [
        "def FE(x):\n",
        "    x = x.drop(['NAME','NAME2', 'Carrier_Code(IATA)', 'Cancelled', 'Diverted', 'Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
        "    x['edt_h'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
        "    x['edt_m'] = x['Estimated_Departure_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
        "    x['eat_h'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[0]))\n",
        "    x['eat_m'] = x['Estimated_Arrival_Time_HH:MM'].apply(lambda x:int(x.split(':')[1]))\n",
        "\n",
        "    x = x.drop(['Estimated_Departure_Time_HH:MM', 'Estimated_Arrival_Time_HH:MM'], axis=1)\n",
        "    \n",
        "    return x\n",
        "\n",
        "train = FE(train)\n",
        "test = FE(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "3EPRQ5WJ1qc7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "train_ar = train.__deepcopy__()\n",
        "test_ar = test.__deepcopy__()\n",
        "\n",
        "label_st = train_ar.drop(columns = ['Delay'])\n",
        "train_st = train_ar[(train_ar['Delay'].astype(str) != 'nan')].drop(columns = ['Delay'])\n",
        "X_nan = train_ar[(train_ar['Delay'].astype(str) == 'nan')].drop(columns = ['Delay'])\n",
        "\n",
        "qual_col = ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline', 'Carrier_ID(DOT)', 'Tail_Number', 'Dep_time_gb',\t'Arr_time_gb',\t'route_gb']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(label_st[i])\n",
        "    for label in np.unique(test[i].dropna()):\n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    train_ar[i] = le.transform(train_ar[i])\n",
        "    train_st[i]=le.transform(train_st[i])\n",
        "    X_nan[i]=le.transform(X_nan[i])\n",
        "    test_ar[i]=le.transform(test_ar[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "cGfwVM8q1qc7",
        "outputId": "32690939-9749-47cf-927c-0cf4a0e6c0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/semi_supervised/_self_training.py:212: UserWarning: y contains no unlabeled samples\n",
            "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelfTrainingClassifier</label><div class=\"sk-toggleable__content\"><pre>SelfTrainingClassifier(base_estimator=RandomForestClassifier(), verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X = train_st\n",
        "y = train_ar[(train_ar['Delay'].astype(str) != 'nan')]['Delay']\n",
        "\n",
        "stclf = SelfTrainingClassifier(\n",
        "    base_estimator = RandomForestClassifier(n_estimators = 100),\n",
        "    verbose = True)\n",
        "\n",
        "stclf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "AS3kZSSb1qc7"
      },
      "outputs": [],
      "source": [
        "X_nan['Delay_pred'] = stclf.predict(X_nan)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_nan['Delay_pred']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg1oikoB-fRU",
        "outputId": "5b95faf8-cece-430f-c4b0-385686eca827"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID\n",
              "TRAIN_000001    Not_Delayed\n",
              "TRAIN_000002    Not_Delayed\n",
              "TRAIN_000003    Not_Delayed\n",
              "TRAIN_000004    Not_Delayed\n",
              "TRAIN_000007    Not_Delayed\n",
              "                   ...     \n",
              "TRAIN_999995    Not_Delayed\n",
              "TRAIN_999996    Not_Delayed\n",
              "TRAIN_999997    Not_Delayed\n",
              "TRAIN_999998    Not_Delayed\n",
              "TRAIN_999999    Not_Delayed\n",
              "Name: Delay_pred, Length: 736317, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "lqu9t4kB1qc8"
      },
      "outputs": [],
      "source": [
        "train_ar.loc[train_ar['Delay'] == 'nan', 'Delay'] = X_nan['Delay_pred']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ar['Delay'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45gZPdt_7hbU",
        "outputId": "a80f0099-0bea-4fa2-a4dc-f9218a5b7f45"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Not_Delayed', 'Delayed'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_ar.drop('Delay', axis=1)\n",
        "y_train = train_ar['Delay']\n",
        "x_test = test_ar"
      ],
      "metadata": {
        "id": "6UsGJywR33_x"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "HikFe3J84PHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "WB6L4Jv64Qv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "L7CLSwggD_Ke"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('3.8.10')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d6ad6a5e467af0c55cd3439f95cdffc9b087666e3ab0338166755486d36b79e1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}